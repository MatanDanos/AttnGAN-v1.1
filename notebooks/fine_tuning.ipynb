{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset.birds_dataset import BirdsDataset\n",
    "from models.discriminator import Discriminator\n",
    "from models.text_encoder import TextEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the tips from the How To Train a GAN video:\n",
    "https://www.youtube.com/watch?v=myGAju4L7O8&t=482s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../test/Example_Dataset/\"\n",
    "base_image_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_image_transforms(base_image_size):\n",
    "    \"\"\"Returns composed image transforms for using on PIL images\"\"\"\n",
    "    resize_factor_for_cropping = 76 / 64 # TODO Understand why they hardcodes this value\n",
    "    new_size = tuple(2*[int(base_image_size * resize_factor_for_cropping)])\n",
    "    image_transforms = transforms.Compose([transforms.Resize(new_size),\n",
    "                                           transforms.RandomCrop(base_image_size),\n",
    "                                           transforms.RandomHorizontalFlip()\n",
    "                                           ])\n",
    "    return image_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1  - Normalized Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Add to unittests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BirdsDataset(dataset_path, split='train', image_transform=compose_image_transforms(base_image_size),\n",
    "                                   base_image_size=base_image_size, number_images=3,\n",
    "                                   text_transform=None, max_caption_length=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.8980)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.draw_random_sample().images[0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9137)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.draw_random_sample().images[0].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 - Avoiding spart gradients by switching frm upsample to ConvTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = torch.nn.ConvTranspose2d(3, 3, 3, stride=2, padding=1, output_padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "us = torch.nn.Upsample(scale_factor=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_dataset[0].images[0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 - Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = (torch.ones(batch_size) * 1)\n",
    "fake_labels = (torch.ones(batch_size) * 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_label_smoothing(real_labels, fake_labels, smooth=0.1):\n",
    "    batch_size = real_labels.shape[0]\n",
    "    smoothed_real = real_labels - smooth * torch.rand(batch_size)\n",
    "    smoothed_fake = fake_labels + smooth * torch.rand(batch_size)\n",
    "    return smoothed_real, smoothed_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9355, 0.9524, 0.9334, 0.9181]),\n",
       " tensor([0.0839, 0.0383, 0.0930, 0.0913]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_label_smoothing(real_labels, fake_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO Wrong labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.any(torch.isnan(torch.tensor(np.inf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = torch.ones(100)\n",
    "fake_labels = torch.zeros(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9003)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(real_labels - smooth * torch.rand_like(real_labels)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0988)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(fake_labels + smooth * torch.rand_like(real_labels)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0314)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.0350)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.randn(10) * 0.02).max()\n",
    "(torch.randn(10) * 0.02).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.randn(2, 3, 64, 64)\n",
    "m2 = torch.randn(2, 3, 64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(110.5243)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean1 = torch.mean(m1, dim=0)\n",
    "mean2 = torch.mean(m2, dim=0)\n",
    "torch.norm(mean1 - mean2, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do Not Delete: Example of masking difference:\n",
    "I think they implemented it wrongly, since the data from a each sample in the batch will contaminate the info in all other samples in the batch. \n",
    "i.e. the seqlen of a single sample affects all other samples.\n",
    "This shouldn't happen.\n",
    "Thus changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "N = 16\n",
    "SEQ_LEN = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.randn(B, N, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 4])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8598, -0.5874, -0.6670,  2.3519],\n",
       "         [-0.7280, -0.1804,  0.7576, -0.5519],\n",
       "         [-0.0641, -2.0211, -0.5546, -0.0865],\n",
       "         [-0.0550,  0.2636,  1.4460, -0.6592],\n",
       "         [-0.3674,  0.2565, -0.3410, -0.6178],\n",
       "         [ 1.1867,  0.7430,  0.0890,  1.7202],\n",
       "         [-0.9460,  0.0776, -1.4905, -0.4916],\n",
       "         [-0.6252,  1.4715,  1.3044,  1.7291],\n",
       "         [ 0.5857, -0.1119, -0.8255,  1.3710],\n",
       "         [-0.6686, -0.2314,  0.2326, -1.1778],\n",
       "         [ 0.9265,  1.7572,  0.1455,  0.3765],\n",
       "         [-0.6366,  1.2138,  0.4201,  1.3872],\n",
       "         [ 0.0313,  1.0288, -0.5221, -1.0860],\n",
       "         [-0.4163,  1.3163, -0.4635, -1.2261],\n",
       "         [ 0.2558,  0.7133, -0.5025,  0.7142],\n",
       "         [-0.1134, -0.7476, -0.1653, -0.7838]],\n",
       "\n",
       "        [[ 0.1064,  0.0189, -0.4552, -1.4402],\n",
       "         [-1.4196, -0.3377, -1.8147, -0.5775],\n",
       "         [ 1.1651, -0.8108,  0.9696, -0.9492],\n",
       "         [ 0.5759, -1.0418, -0.5664, -0.1953],\n",
       "         [ 1.3160,  0.0754, -1.3854,  0.2612],\n",
       "         [-1.8174,  2.0885, -2.0089,  1.7635],\n",
       "         [-1.8500, -1.4816,  0.4283, -0.0578],\n",
       "         [ 1.1888, -0.2216,  0.5765, -1.1005],\n",
       "         [ 0.1816, -0.4847, -0.7243,  0.1645],\n",
       "         [-0.2255, -0.9748, -1.7492,  1.3678],\n",
       "         [-0.1529,  0.9994, -2.3118, -0.4184],\n",
       "         [ 1.0685,  2.9052,  0.5542, -0.0739],\n",
       "         [-0.5427, -0.7300,  0.3536, -0.1176],\n",
       "         [-0.0294, -1.7607,  1.8553,  0.2747],\n",
       "         [ 1.2237, -0.5756,  1.0534, -0.4433],\n",
       "         [ 1.2416,  0.9184,  0.1112,  2.6733]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.Tensor([[0, 0, 0, 1],\n",
    "                     [0, 0, 1, 1]])\n",
    "mask = mask.type(torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mask.shape == torch.Size([B, SEQ_LEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 1],\n",
       "        [0, 0, 1, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The important part!!!!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask = mask.unsqueeze(1)\n",
    "new_S = S.data.masked_fill_(new_mask.data, -float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8598, -0.5874, -0.6670,    -inf],\n",
       "         [-0.7280, -0.1804,  0.7576,    -inf],\n",
       "         [-0.0641, -2.0211, -0.5546,    -inf],\n",
       "         [-0.0550,  0.2636,  1.4460,    -inf],\n",
       "         [-0.3674,  0.2565, -0.3410,    -inf],\n",
       "         [ 1.1867,  0.7430,  0.0890,    -inf],\n",
       "         [-0.9460,  0.0776, -1.4905,    -inf],\n",
       "         [-0.6252,  1.4715,  1.3044,    -inf],\n",
       "         [ 0.5857, -0.1119, -0.8255,    -inf],\n",
       "         [-0.6686, -0.2314,  0.2326,    -inf],\n",
       "         [ 0.9265,  1.7572,  0.1455,    -inf],\n",
       "         [-0.6366,  1.2138,  0.4201,    -inf],\n",
       "         [ 0.0313,  1.0288, -0.5221,    -inf],\n",
       "         [-0.4163,  1.3163, -0.4635,    -inf],\n",
       "         [ 0.2558,  0.7133, -0.5025,    -inf],\n",
       "         [-0.1134, -0.7476, -0.1653,    -inf]],\n",
       "\n",
       "        [[ 0.1064,  0.0189,    -inf,    -inf],\n",
       "         [-1.4196, -0.3377,    -inf,    -inf],\n",
       "         [ 1.1651, -0.8108,    -inf,    -inf],\n",
       "         [ 0.5759, -1.0418,    -inf,    -inf],\n",
       "         [ 1.3160,  0.0754,    -inf,    -inf],\n",
       "         [-1.8174,  2.0885,    -inf,    -inf],\n",
       "         [-1.8500, -1.4816,    -inf,    -inf],\n",
       "         [ 1.1888, -0.2216,    -inf,    -inf],\n",
       "         [ 0.1816, -0.4847,    -inf,    -inf],\n",
       "         [-0.2255, -0.9748,    -inf,    -inf],\n",
       "         [-0.1529,  0.9994,    -inf,    -inf],\n",
       "         [ 1.0685,  2.9052,    -inf,    -inf],\n",
       "         [-0.5427, -0.7300,    -inf,    -inf],\n",
       "         [-0.0294, -1.7607,    -inf,    -inf],\n",
       "         [ 1.2237, -0.5756,    -inf,    -inf],\n",
       "         [ 1.2416,  0.9184,    -inf,    -inf]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8598, -0.5874, -0.6670,    -inf],\n",
       "         [-0.7280, -0.1804,  0.7576,    -inf],\n",
       "         [-0.0641, -2.0211, -0.5546,    -inf],\n",
       "         [-0.0550,  0.2636,  1.4460,    -inf],\n",
       "         [-0.3674,  0.2565, -0.3410,    -inf],\n",
       "         [ 1.1867,  0.7430,  0.0890,    -inf],\n",
       "         [-0.9460,  0.0776, -1.4905,    -inf],\n",
       "         [-0.6252,  1.4715,  1.3044,    -inf],\n",
       "         [ 0.5857, -0.1119, -0.8255,    -inf],\n",
       "         [-0.6686, -0.2314,  0.2326,    -inf],\n",
       "         [ 0.9265,  1.7572,  0.1455,    -inf],\n",
       "         [-0.6366,  1.2138,  0.4201,    -inf],\n",
       "         [ 0.0313,  1.0288, -0.5221,    -inf],\n",
       "         [-0.4163,  1.3163, -0.4635,    -inf],\n",
       "         [ 0.2558,  0.7133, -0.5025,    -inf],\n",
       "         [-0.1134, -0.7476, -0.1653,    -inf]],\n",
       "\n",
       "        [[ 0.1064,  0.0189,    -inf,    -inf],\n",
       "         [-1.4196, -0.3377,    -inf,    -inf],\n",
       "         [ 1.1651, -0.8108,    -inf,    -inf],\n",
       "         [ 0.5759, -1.0418,    -inf,    -inf],\n",
       "         [ 1.3160,  0.0754,    -inf,    -inf],\n",
       "         [-1.8174,  2.0885,    -inf,    -inf],\n",
       "         [-1.8500, -1.4816,    -inf,    -inf],\n",
       "         [ 1.1888, -0.2216,    -inf,    -inf],\n",
       "         [ 0.1816, -0.4847,    -inf,    -inf],\n",
       "         [-0.2255, -0.9748,    -inf,    -inf],\n",
       "         [-0.1529,  0.9994,    -inf,    -inf],\n",
       "         [ 1.0685,  2.9052,    -inf,    -inf],\n",
       "         [-0.5427, -0.7300,    -inf,    -inf],\n",
       "         [-0.0294, -1.7607,    -inf,    -inf],\n",
       "         [ 1.2237, -0.5756,    -inf,    -inf],\n",
       "         [ 1.2416,  0.9184,    -inf,    -inf]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the above code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16, 4])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_S.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8598, -0.5874, -0.6670,    -inf],\n",
       "         [-0.7280, -0.1804,  0.7576,    -inf],\n",
       "         [-0.0641, -2.0211, -0.5546,    -inf],\n",
       "         [-0.0550,  0.2636,  1.4460,    -inf],\n",
       "         [-0.3674,  0.2565, -0.3410,    -inf],\n",
       "         [ 1.1867,  0.7430,  0.0890,    -inf],\n",
       "         [-0.9460,  0.0776, -1.4905,    -inf],\n",
       "         [-0.6252,  1.4715,  1.3044,    -inf],\n",
       "         [ 0.5857, -0.1119, -0.8255,    -inf],\n",
       "         [-0.6686, -0.2314,  0.2326,    -inf],\n",
       "         [ 0.9265,  1.7572,  0.1455,    -inf],\n",
       "         [-0.6366,  1.2138,  0.4201,    -inf],\n",
       "         [ 0.0313,  1.0288, -0.5221,    -inf],\n",
       "         [-0.4163,  1.3163, -0.4635,    -inf],\n",
       "         [ 0.2558,  0.7133, -0.5025,    -inf],\n",
       "         [-0.1134, -0.7476, -0.1653,    -inf]],\n",
       "\n",
       "        [[ 0.1064,  0.0189,    -inf,    -inf],\n",
       "         [-1.4196, -0.3377,    -inf,    -inf],\n",
       "         [ 1.1651, -0.8108,    -inf,    -inf],\n",
       "         [ 0.5759, -1.0418,    -inf,    -inf],\n",
       "         [ 1.3160,  0.0754,    -inf,    -inf],\n",
       "         [-1.8174,  2.0885,    -inf,    -inf],\n",
       "         [-1.8500, -1.4816,    -inf,    -inf],\n",
       "         [ 1.1888, -0.2216,    -inf,    -inf],\n",
       "         [ 0.1816, -0.4847,    -inf,    -inf],\n",
       "         [-0.2255, -0.9748,    -inf,    -inf],\n",
       "         [-0.1529,  0.9994,    -inf,    -inf],\n",
       "         [ 1.0685,  2.9052,    -inf,    -inf],\n",
       "         [-0.5427, -0.7300,    -inf,    -inf],\n",
       "         [-0.0294, -1.7607,    -inf,    -inf],\n",
       "         [ 1.2237, -0.5756,    -inf,    -inf],\n",
       "         [ 1.2416,  0.9184,    -inf,    -inf]]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_S = torch.exp(new_S) / torch.sum(torch.exp(new_S), dim=2, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6885, 0.1619, 0.1496, 0.0000],\n",
       "         [0.1399, 0.2419, 0.6181, 0.0000],\n",
       "         [0.5703, 0.0806, 0.3492, 0.0000],\n",
       "         [0.1457, 0.2004, 0.6538, 0.0000],\n",
       "         [0.2569, 0.4794, 0.2637, 0.0000],\n",
       "         [0.5063, 0.3248, 0.1689, 0.0000],\n",
       "         [0.2292, 0.6379, 0.1330, 0.0000],\n",
       "         [0.0624, 0.5079, 0.4297, 0.0000],\n",
       "         [0.5742, 0.2858, 0.1400, 0.0000],\n",
       "         [0.1996, 0.3090, 0.4914, 0.0000],\n",
       "         [0.2665, 0.6115, 0.1220, 0.0000],\n",
       "         [0.0977, 0.6214, 0.2810, 0.0000],\n",
       "         [0.2333, 0.6326, 0.1341, 0.0000],\n",
       "         [0.1314, 0.7432, 0.1254, 0.0000],\n",
       "         [0.3280, 0.5183, 0.1537, 0.0000],\n",
       "         [0.4033, 0.2139, 0.3829, 0.0000]],\n",
       "\n",
       "        [[0.5219, 0.4781, 0.0000, 0.0000],\n",
       "         [0.2531, 0.7469, 0.0000, 0.0000],\n",
       "         [0.8782, 0.1218, 0.0000, 0.0000],\n",
       "         [0.8345, 0.1655, 0.0000, 0.0000],\n",
       "         [0.7757, 0.2243, 0.0000, 0.0000],\n",
       "         [0.0197, 0.9803, 0.0000, 0.0000],\n",
       "         [0.4089, 0.5911, 0.0000, 0.0000],\n",
       "         [0.8038, 0.1962, 0.0000, 0.0000],\n",
       "         [0.6607, 0.3393, 0.0000, 0.0000],\n",
       "         [0.6790, 0.3210, 0.0000, 0.0000],\n",
       "         [0.2401, 0.7599, 0.0000, 0.0000],\n",
       "         [0.1374, 0.8626, 0.0000, 0.0000],\n",
       "         [0.5467, 0.4533, 0.0000, 0.0000],\n",
       "         [0.8496, 0.1504, 0.0000, 0.0000],\n",
       "         [0.8581, 0.1419, 0.0000, 0.0000],\n",
       "         [0.5801, 0.4199, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = torch.randn(B, 128, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6885, 0.1399, 0.5703, 0.1457, 0.2569, 0.5063, 0.2292, 0.0624,\n",
       "          0.5742, 0.1996, 0.2665, 0.0977, 0.2333, 0.1314, 0.3280, 0.4033],\n",
       "         [0.1619, 0.2419, 0.0806, 0.2004, 0.4794, 0.3248, 0.6379, 0.5079,\n",
       "          0.2858, 0.3090, 0.6115, 0.6214, 0.6326, 0.7432, 0.5183, 0.2139],\n",
       "         [0.1496, 0.6181, 0.3492, 0.6538, 0.2637, 0.1689, 0.1330, 0.4297,\n",
       "          0.1400, 0.4914, 0.1220, 0.2810, 0.1341, 0.1254, 0.1537, 0.3829],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "        [[0.5219, 0.2531, 0.8782, 0.8345, 0.7757, 0.0197, 0.4089, 0.8038,\n",
       "          0.6607, 0.6790, 0.2401, 0.1374, 0.5467, 0.8496, 0.8581, 0.5801],\n",
       "         [0.4781, 0.7469, 0.1218, 0.1655, 0.2243, 0.9803, 0.5911, 0.1962,\n",
       "          0.3393, 0.3210, 0.7599, 0.8626, 0.4533, 0.1504, 0.1419, 0.4199],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_S.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = torch.bmm(values, final_S.transpose(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 16])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What in their code was supposed to happen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = torch.randn(B, N, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_target = S.view(B * N, SEQ_LEN)\n",
    "mask_target = mask.repeat(N, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_target = s_target.data.masked_fill_(mask_target.data, -float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0721,  0.3769,  0.8276,    -inf],\n",
       "        [ 1.1037,  0.2412,    -inf,    -inf],\n",
       "        [ 0.2906,  0.5414,  0.1116,    -inf],\n",
       "        [ 0.5539,  0.5204,    -inf,    -inf],\n",
       "        [ 0.9170, -0.0896, -2.3579,    -inf],\n",
       "        [-0.2896,  0.1527,    -inf,    -inf],\n",
       "        [ 1.1611,  1.0140, -1.1554,    -inf],\n",
       "        [ 0.1728, -0.4008,    -inf,    -inf],\n",
       "        [ 0.3642, -0.2595,  2.7537,    -inf],\n",
       "        [ 1.1848, -0.3510,    -inf,    -inf],\n",
       "        [-0.2630,  0.3359, -1.1433,    -inf],\n",
       "        [-0.1059,  0.7815,    -inf,    -inf],\n",
       "        [-0.5517, -1.1202, -0.5394,    -inf],\n",
       "        [-1.3095, -0.1720,    -inf,    -inf],\n",
       "        [-0.7143, -0.3530, -2.3358,    -inf],\n",
       "        [-1.3454, -0.0322,    -inf,    -inf],\n",
       "        [ 0.8054,  0.6466, -1.2950,    -inf],\n",
       "        [-0.6130,  0.0538,    -inf,    -inf],\n",
       "        [-1.4917, -0.0735,  0.0297,    -inf],\n",
       "        [-0.9626,  0.8355,    -inf,    -inf],\n",
       "        [-0.5957, -1.2979,  3.6472,    -inf],\n",
       "        [-0.7035, -2.0725,    -inf,    -inf],\n",
       "        [ 1.4871, -0.4349,  0.6619,    -inf],\n",
       "        [ 0.4006, -1.3694,    -inf,    -inf],\n",
       "        [ 0.9240, -1.3604, -0.7307,    -inf],\n",
       "        [-1.2875,  0.7155,    -inf,    -inf],\n",
       "        [ 0.4637, -1.4366,  2.3233,    -inf],\n",
       "        [ 0.2509,  1.0906,    -inf,    -inf],\n",
       "        [-0.1129, -0.0084,  0.7251,    -inf],\n",
       "        [ 0.0114, -1.1038,    -inf,    -inf],\n",
       "        [ 1.0565, -0.1125, -0.8415,    -inf],\n",
       "        [ 0.8343,  1.1037,    -inf,    -inf]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0721,  0.3769,  0.8276,    -inf],\n",
       "         [ 1.1037,  0.2412,    -inf,    -inf],\n",
       "         [ 0.2906,  0.5414,  0.1116,    -inf],\n",
       "         [ 0.5539,  0.5204,    -inf,    -inf],\n",
       "         [ 0.9170, -0.0896, -2.3579,    -inf],\n",
       "         [-0.2896,  0.1527,    -inf,    -inf],\n",
       "         [ 1.1611,  1.0140, -1.1554,    -inf],\n",
       "         [ 0.1728, -0.4008,    -inf,    -inf],\n",
       "         [ 0.3642, -0.2595,  2.7537,    -inf],\n",
       "         [ 1.1848, -0.3510,    -inf,    -inf],\n",
       "         [-0.2630,  0.3359, -1.1433,    -inf],\n",
       "         [-0.1059,  0.7815,    -inf,    -inf],\n",
       "         [-0.5517, -1.1202, -0.5394,    -inf],\n",
       "         [-1.3095, -0.1720,    -inf,    -inf],\n",
       "         [-0.7143, -0.3530, -2.3358,    -inf],\n",
       "         [-1.3454, -0.0322,    -inf,    -inf]],\n",
       "\n",
       "        [[ 0.8054,  0.6466, -1.2950,    -inf],\n",
       "         [-0.6130,  0.0538,    -inf,    -inf],\n",
       "         [-1.4917, -0.0735,  0.0297,    -inf],\n",
       "         [-0.9626,  0.8355,    -inf,    -inf],\n",
       "         [-0.5957, -1.2979,  3.6472,    -inf],\n",
       "         [-0.7035, -2.0725,    -inf,    -inf],\n",
       "         [ 1.4871, -0.4349,  0.6619,    -inf],\n",
       "         [ 0.4006, -1.3694,    -inf,    -inf],\n",
       "         [ 0.9240, -1.3604, -0.7307,    -inf],\n",
       "         [-1.2875,  0.7155,    -inf,    -inf],\n",
       "         [ 0.4637, -1.4366,  2.3233,    -inf],\n",
       "         [ 0.2509,  1.0906,    -inf,    -inf],\n",
       "         [-0.1129, -0.0084,  0.7251,    -inf],\n",
       "         [ 0.0114, -1.1038,    -inf,    -inf],\n",
       "         [ 1.0565, -0.1125, -0.8415,    -inf],\n",
       "         [ 0.8343,  1.1037,    -inf,    -inf]]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = s_target.view(B, N, SEQ_LEN)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
