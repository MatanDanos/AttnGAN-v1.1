{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class for the Cub dataset\n",
    "The data we will work on should be in the `preprocessing` directory, and should include the following:\n",
    "1. `./images` directory, with all bird images divided into the 200 categories\n",
    "2. `./text` directory, with all the bird images captions divided into the 200 categories\n",
    "3. `./images.csv` - csv file containing the path, image_id, class id, and train/test affiliation of each image\n",
    "4. `./classes.csv` - csv file containing a mapping between the class id and the class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.birds_dataset import BirdsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset_path = \"/home/user_2/AttnGAN/datasets\"\n",
    "\n",
    "dataset_interim_path = os.path.join(base_dataset_path, \"interim\")\n",
    "dataset_preprocess_path = os.path.join(base_dataset_path, \"preprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing unzipped files\n",
    "All unzipped files are in the `interim` data folder and should be organized and moved to the `preprocessing` folder.\n",
    "Follow the following 4 steps to get the right order of the `preprocessing folder`\n",
    "\n",
    "### 0 \n",
    "Unzip the `bird.zip` and `CUB_200_2011.tgz` to the `interim` directory and put everything in the base directory if you havn't already done so.\n",
    "\n",
    "### 1\n",
    "Move manually the `./images` with all the images folder to `preprocessing` folder\n",
    "\n",
    "### 2\n",
    "Move manually the `./text` folder with all the text captions for each image to the `preprocessing` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3\n",
    "Saving the images as .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.read_csv(os.path.join(dataset_interim_path, \"images.txt\"), sep=\" \", names=[\"image_id\", \"path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                               path\n",
       "0         1  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
       "1         2  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
       "2         3  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
       "3         4  001.Black_footed_Albatross/Black_Footed_Albatr...\n",
       "4         5  001.Black_footed_Albatross/Black_Footed_Albatr..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another column to hold the class id\n",
    "images_df[\"class_id\"] = images_df.apply(lambda p : int(p.path[:3]), axis=1)\n",
    "\n",
    "# remove the .jpg from the end of the path\n",
    "images_df[\"path\"] = images_df.apply(lambda p : p.path[:-4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another column to hold the train/test affiliation of the image\n",
    "# 1 - The image is in the training set.\n",
    "# 0 - the image is in the test set.\n",
    "train_test_split = pd.read_csv(os.path.join(dataset_interim_path, \"train_test_split.txt\"), sep=\" \", names=[\"img_id\", \"is_train\"])\n",
    "images_df[\"is_train\"] = train_test_split.is_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>class_id</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                               path  class_id  \\\n",
       "0         1  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "1         2  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "2         3  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "3         4  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "4         5  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "\n",
       "   is_train  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final unified csv file\n",
    "images_df.to_csv(os.path.join(dataset_preprocess_path, \"images.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4\n",
    "Saving the class name to class index mapping as csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df = pd.read_csv(os.path.join(dataset_interim_path, \"classes.txt\"), sep=\" \", names=[\"class_id\", \"class_name\"])\n",
    "classes_df.to_csv(os.path.join(dataset_preprocess_path, \"classes.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more metadata\n",
    "- [ ] What is it used for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (os.path.join(dataset_interim_path, \"train\", \"filenames.pickle\"), \"rb\") as f:\n",
    "    train_filenames = pickle.load(f)\n",
    "\n",
    "with open (os.path.join(dataset_interim_path, \"train\", \"class_info.pickle\"), \"rb\") as f1:\n",
    "    train_class_info = pickle.load(f1, encoding=\"latin1\")\n",
    "\n",
    "with open (os.path.join(dataset_interim_path, \"test\", \"filenames.pickle\"), \"rb\") as f:\n",
    "    test_filenames = pickle.load(f)\n",
    "\n",
    "with open (os.path.join(dataset_interim_path, \"test\", \"class_info.pickle\"), \"rb\") as f:\n",
    "    test_class_info = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use a pre-trained model:\n",
    "# with open(os.path.join(dataset_interim_path, \"captions.pickle\"), \"rb\") as f:\n",
    "#     captions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class to help load the data\n",
    "Base path should be after the initial one-time ordering of the data folder.  \n",
    "Ordered data that should be taken by this class should be in the `preprocessing` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df = pd.read_csv(os.path.join(dataset_preprocess_path, \"classes.csv\")).drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_id</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>002.Laysan_Albatross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>003.Sooty_Albatross</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>004.Groove_billed_Ani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>005.Crested_Auklet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_id                  class_name\n",
       "0         1  001.Black_footed_Albatross\n",
       "1         2        002.Laysan_Albatross\n",
       "2         3         003.Sooty_Albatross\n",
       "3         4       004.Groove_billed_Ani\n",
       "4         5          005.Crested_Auklet"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_df = pd.read_csv(os.path.join(dataset_preprocess_path, \"images.csv\")).drop(\"Unnamed: 0\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>class_id</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                               path  class_id  \\\n",
       "0         1  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "1         2  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "2         3  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "3         4  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "4         5  001.Black_footed_Albatross/Black_Footed_Albatr...         1   \n",
       "\n",
       "   is_train  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sampels = len(images_df)\n",
    "num_train = images_df.is_train.sum()\n",
    "num_test = total_sampels - num_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 5,994 training samples, and 5,794 test samples\n"
     ]
    }
   ],
   "source": [
    "print(\"There are {:,} training samples, and {:,} test samples\".format(num_train, num_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11788"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5994  + 5794"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = images_df[images_df.is_train == 1].drop(\"is_train\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>001.Black_footed_Albatross/Black_Footed_Albatr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   image_id                                               path  class_id\n",
       "1         2  001.Black_footed_Albatross/Black_Footed_Albatr...         1\n",
       "3         4  001.Black_footed_Albatross/Black_Footed_Albatr...         1\n",
       "4         5  001.Black_footed_Albatross/Black_Footed_Albatr...         1\n",
       "6         7  001.Black_footed_Albatross/Black_Footed_Albatr...         1\n",
       "7         8  001.Black_footed_Albatross/Black_Footed_Albatr...         1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_transforms = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_dataset = BirdsDataset(dataset_preprocess_path, split=\"train\", image_transform=image_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pad>'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bird_dataset.vocabulary.itos[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(bird_dataset, shuffle=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'caption': tensor([[  1,  10, 213,   6,  13,  83,   7,   9,   5,  18, 164,   5,   8,   4,\n",
       "           30,  14,   2,   2,   2,   2],\n",
       "         [  1,  10,   6,   8,   4,  30,  71,  20,   4,  11,  24,   5,   4,  11,\n",
       "           37,   2,   2,   2,   2,   2],\n",
       "         [  1,  10,   6,  13,  49,   7,  33,   5,   8,   4,  43,  30,  14,   2,\n",
       "            2,   2,   2,   2,   2,   2],\n",
       "         [  1,   4,  16,  50,  49,   6,   7, 114,  49,  78,   5,   4,  45,   9,\n",
       "           20,   2,   2,   2,   2,   2]]),\n",
       " 'caption_length': tensor([15, 14, 12, 14]),\n",
       " 'class_id': tensor([176,  45,  15, 153]),\n",
       " 'image': tensor([[[[0.3843, 0.3961, 0.4000,  ..., 0.3216, 0.3294, 0.3412],\n",
       "           [0.4000, 0.3961, 0.4000,  ..., 0.3137, 0.3333, 0.3294],\n",
       "           [0.3882, 0.3882, 0.4039,  ..., 0.3216, 0.3176, 0.3137],\n",
       "           ...,\n",
       "           [0.4039, 0.5255, 0.6235,  ..., 0.2824, 0.2902, 0.2902],\n",
       "           [0.4549, 0.5686, 0.5765,  ..., 0.2784, 0.2980, 0.2863],\n",
       "           [0.4196, 0.5137, 0.5216,  ..., 0.3608, 0.3098, 0.2745]],\n",
       " \n",
       "          [[0.6902, 0.6863, 0.6824,  ..., 0.5804, 0.5686, 0.5608],\n",
       "           [0.6863, 0.6824, 0.6824,  ..., 0.5725, 0.5686, 0.5608],\n",
       "           [0.6706, 0.6784, 0.6902,  ..., 0.5686, 0.5647, 0.5686],\n",
       "           ...,\n",
       "           [0.6431, 0.6745, 0.7529,  ..., 0.5333, 0.5412, 0.5490],\n",
       "           [0.6745, 0.7490, 0.7569,  ..., 0.5294, 0.5451, 0.5529],\n",
       "           [0.6627, 0.7216, 0.7294,  ..., 0.5451, 0.5373, 0.5412]],\n",
       " \n",
       "          [[0.2941, 0.2980, 0.2941,  ..., 0.0863, 0.0745, 0.0941],\n",
       "           [0.2902, 0.2902, 0.2902,  ..., 0.1137, 0.0941, 0.0863],\n",
       "           [0.2863, 0.2941, 0.3059,  ..., 0.1176, 0.0902, 0.0784],\n",
       "           ...,\n",
       "           [0.1333, 0.2039, 0.3176,  ..., 0.0431, 0.0510, 0.0588],\n",
       "           [0.2471, 0.3608, 0.3922,  ..., 0.0275, 0.0235, 0.0314],\n",
       "           [0.2588, 0.3569, 0.3961,  ..., 0.0627, 0.0588, 0.0431]]],\n",
       " \n",
       " \n",
       "         [[[0.5412, 0.5490, 0.5490,  ..., 0.5529, 0.5529, 0.5569],\n",
       "           [0.5451, 0.5490, 0.5490,  ..., 0.5490, 0.5569, 0.5529],\n",
       "           [0.5490, 0.5451, 0.5451,  ..., 0.5529, 0.5569, 0.5529],\n",
       "           ...,\n",
       "           [0.5373, 0.5412, 0.5412,  ..., 0.5333, 0.5373, 0.5373],\n",
       "           [0.5333, 0.5333, 0.5373,  ..., 0.5373, 0.5373, 0.5373],\n",
       "           [0.5333, 0.5373, 0.5373,  ..., 0.5412, 0.5412, 0.5412]],\n",
       " \n",
       "          [[0.6824, 0.6902, 0.6902,  ..., 0.6941, 0.6941, 0.6980],\n",
       "           [0.6863, 0.6902, 0.6902,  ..., 0.6902, 0.6980, 0.6941],\n",
       "           [0.6902, 0.6863, 0.6863,  ..., 0.6941, 0.6980, 0.6941],\n",
       "           ...,\n",
       "           [0.6706, 0.6745, 0.6745,  ..., 0.6667, 0.6706, 0.6706],\n",
       "           [0.6667, 0.6667, 0.6706,  ..., 0.6627, 0.6667, 0.6706],\n",
       "           [0.6667, 0.6706, 0.6706,  ..., 0.6627, 0.6667, 0.6667]],\n",
       " \n",
       "          [[0.7843, 0.7922, 0.7922,  ..., 0.7961, 0.7961, 0.8000],\n",
       "           [0.7882, 0.7922, 0.7922,  ..., 0.7922, 0.8000, 0.7961],\n",
       "           [0.7922, 0.7882, 0.7882,  ..., 0.7961, 0.8000, 0.7961],\n",
       "           ...,\n",
       "           [0.7765, 0.7804, 0.7804,  ..., 0.7725, 0.7765, 0.7765],\n",
       "           [0.7686, 0.7725, 0.7765,  ..., 0.7725, 0.7765, 0.7765],\n",
       "           [0.7686, 0.7765, 0.7725,  ..., 0.7725, 0.7765, 0.7765]]],\n",
       " \n",
       " \n",
       "         [[[0.1569, 0.3843, 0.6431,  ..., 0.4745, 0.5255, 0.5647],\n",
       "           [0.1765, 0.4000, 0.6431,  ..., 0.5294, 0.5451, 0.5608],\n",
       "           [0.1804, 0.3961, 0.6157,  ..., 0.5725, 0.6118, 0.6471],\n",
       "           ...,\n",
       "           [0.1451, 0.1216, 0.1490,  ..., 0.3059, 0.3137, 0.2980],\n",
       "           [0.1373, 0.1255, 0.1176,  ..., 0.2667, 0.2902, 0.2902],\n",
       "           [0.1843, 0.1608, 0.1686,  ..., 0.2784, 0.2863, 0.3020]],\n",
       " \n",
       "          [[0.2431, 0.5922, 0.6392,  ..., 0.5255, 0.5569, 0.6118],\n",
       "           [0.2745, 0.5843, 0.6392,  ..., 0.5569, 0.5961, 0.6275],\n",
       "           [0.2745, 0.5686, 0.6275,  ..., 0.5686, 0.6157, 0.6471],\n",
       "           ...,\n",
       "           [0.2157, 0.2078, 0.1961,  ..., 0.3882, 0.3922, 0.3961],\n",
       "           [0.1804, 0.1647, 0.1569,  ..., 0.3529, 0.3569, 0.3490],\n",
       "           [0.1529, 0.1373, 0.1373,  ..., 0.3020, 0.3059, 0.3137]],\n",
       " \n",
       "          [[0.2000, 0.4745, 0.5882,  ..., 0.4941, 0.5529, 0.6118],\n",
       "           [0.1961, 0.4431, 0.5765,  ..., 0.5412, 0.5922, 0.6235],\n",
       "           [0.2118, 0.4549, 0.5608,  ..., 0.5529, 0.6196, 0.6471],\n",
       "           ...,\n",
       "           [0.1255, 0.1255, 0.1216,  ..., 0.3490, 0.3373, 0.3569],\n",
       "           [0.0706, 0.0706, 0.0824,  ..., 0.3176, 0.3137, 0.3020],\n",
       "           [0.0431, 0.0706, 0.0824,  ..., 0.3020, 0.2824, 0.2745]]],\n",
       " \n",
       " \n",
       "         [[[0.3216, 0.4353, 0.4039,  ..., 0.0784, 0.0745, 0.0627],\n",
       "           [0.5686, 0.6549, 0.6353,  ..., 0.0824, 0.0745, 0.0706],\n",
       "           [0.7255, 0.7725, 0.7608,  ..., 0.0745, 0.0784, 0.0745],\n",
       "           ...,\n",
       "           [0.9176, 0.8314, 0.8706,  ..., 0.2588, 0.2627, 0.2627],\n",
       "           [0.8824, 0.8039, 0.8157,  ..., 0.2510, 0.2549, 0.2627],\n",
       "           [0.7961, 0.8471, 0.8431,  ..., 0.2431, 0.2510, 0.2588]],\n",
       " \n",
       "          [[0.3686, 0.4745, 0.4353,  ..., 0.1176, 0.1137, 0.1137],\n",
       "           [0.5647, 0.6549, 0.6314,  ..., 0.1176, 0.1137, 0.1137],\n",
       "           [0.7059, 0.7647, 0.7569,  ..., 0.1255, 0.1216, 0.1137],\n",
       "           ...,\n",
       "           [0.9255, 0.8353, 0.8510,  ..., 0.3765, 0.3765, 0.3804],\n",
       "           [0.8863, 0.7961, 0.7961,  ..., 0.3686, 0.3725, 0.3725],\n",
       "           [0.7686, 0.8039, 0.7765,  ..., 0.3647, 0.3686, 0.3686]],\n",
       " \n",
       "          [[0.3294, 0.4431, 0.4039,  ..., 0.0549, 0.0510, 0.0471],\n",
       "           [0.5647, 0.6588, 0.6314,  ..., 0.0549, 0.0549, 0.0471],\n",
       "           [0.7176, 0.7804, 0.7647,  ..., 0.0549, 0.0588, 0.0510],\n",
       "           ...,\n",
       "           [0.9608, 0.8745, 0.8745,  ..., 0.1765, 0.1765, 0.1765],\n",
       "           [0.9176, 0.8314, 0.8157,  ..., 0.1686, 0.1725, 0.1804],\n",
       "           [0.7961, 0.8392, 0.8039,  ..., 0.1608, 0.1686, 0.1765]]]]),\n",
       " 'image_id': tensor([10350,  2535,   790,  8970])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n",
      "tensor([10350,  2535,   790,  8970])\n",
      "tensor([176,  45,  15, 153])\n",
      "tensor([  1,  10, 213,   6,  13,  83,   7,   9,   5,  18, 164,   5,   8,   4,\n",
      "         30,  14,   2,   2,   2,   2])\n"
     ]
    }
   ],
   "source": [
    "print(batch[\"image\"].shape)\n",
    "print(batch[\"image_id\"])\n",
    "print(batch[\"class_id\"])\n",
    "print(batch[\"caption\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the bad text sentences\n",
    "Run all these to clean bad lines when done creatign the preprocessing directory.  \n",
    "similary, can just load the bad_files.pkl.gz and use it with the last cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "from dataset.preprocessing import clean_text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['��', '��', '��', '��', '��', '��', '��', '��', '��', '��', '��', '��', '��']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_unknown_chars_regex = re.compile(r'[��]+')\n",
    "# collapse_unknown_chars_regex.findall(\"this��bird��has��a��yellow-green��belly,��a��black��crown��and��a��short,��pointy��bill.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./list_of_bad_filenames.pkl.gz']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = \"/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text\"\n",
    "collapse_unknown_chars_regex = re.compile(r'[��]+')\n",
    "bad_files = []\n",
    "for dirname in os.listdir(base_path):\n",
    "    for filename in os.listdir(os.path.join(base_path, dirname)):\n",
    "        full_filepath = os.path.join(base_path, dirname, filename)\n",
    "        with open(full_filepath, 'r') as f:\n",
    "            if any([collapse_unknown_chars_regex.findall(line) for line in f.readlines()]):\n",
    "                bad_files.append(full_filepath)\n",
    "joblib.dump(bad_files, \"./list_of_bad_filenames.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_unknown_chars_regex = re.compile(r'[��]+')\n",
    "for bad_file in bad_files:\n",
    "    new_lines = []\n",
    "    with open(bad_file, \"r\") as f:\n",
    "        bad_lines = f.readlines()\n",
    "        for bad_line in bad_lines:\n",
    "            new_lines.append(collapse_unknown_chars_regex.sub(' ', bad_line))\n",
    "    os.remove(bad_file)\n",
    "    with open(bad_file, \"w\") as f2:\n",
    "        for good_line in new_lines:\n",
    "            f2.write(good_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/177.Prothonotary_Warbler/Prothonotary_Warbler_0083_173929.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/177.Prothonotary_Warbler/Prothonotary_Warbler_0106_174221.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/055.Evening_Grosbeak/Evening_Grosbeak_0022_37761.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/067.Anna_Hummingbird/Anna_Hummingbird_0070_56085.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/038.Great_Crested_Flycatcher/Great_Crested_Flycatcher_0016_29406.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/187.American_Three_toed_Woodpecker/American_Three_Toed_Woodpecker_0014_179882.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/009.Brewer_Blackbird/Brewer_Blackbird_0079_2343.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/009.Brewer_Blackbird/Brewer_Blackbird_0115_2279.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/159.Black_and_white_Warbler/Black_And_White_Warbler_0078_160365.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/154.Red_eyed_Vireo/Red_Eyed_Vireo_0074_157170.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/147.Least_Tern/Least_Tern_0050_153254.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/172.Nashville_Warbler/Nashville_Warbler_0056_167123.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/160.Black_throated_Blue_Warbler/Black_Throated_Blue_Warbler_0086_161716.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/160.Black_throated_Blue_Warbler/Black_Throated_Blue_Warbler_0137_161207.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/148.Green_tailed_Towhee/Green_Tailed_Towhee_0037_797405.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/095.Baltimore_Oriole/Baltimore_Oriole_0092_87435.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/072.Pomarine_Jaeger/Pomarine_Jaeger_0026_61273.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/033.Yellow_billed_Cuckoo/Yellow_Billed_Cuckoo_0026_26794.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/199.Winter_Wren/Winter_Wren_0112_189507.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/138.Tree_Swallow/Tree_Swallow_0030_134942.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/186.Cedar_Waxwing/Cedar_Waxwing_0054_178141.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/139.Scarlet_Tanager/Scarlet_Tanager_0089_138281.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/092.Nighthawk/Nighthawk_0054_795337.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/003.Sooty_Albatross/Sooty_Albatross_0029_796357.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/070.Green_Violetear/Green_Violetear_0064_795661.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/070.Green_Violetear/Green_Violetear_0119_795724.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/155.Warbling_Vireo/Warbling_Vireo_0090_158403.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/155.Warbling_Vireo/Warbling_Vireo_0064_158437.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/080.Green_Kingfisher/Green_Kingfisher_0053_71319.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/180.Wilson_Warbler/Wilson_Warbler_0083_175253.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/180.Wilson_Warbler/Wilson_Warbler_0043_175491.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/191.Red_headed_Woodpecker/Red_Headed_Woodpecker_0099_183524.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/153.Philadelphia_Vireo/Philadelphia_Vireo_0043_794792.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/153.Philadelphia_Vireo/Philadelphia_Vireo_0012_794785.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/134.Cape_Glossy_Starling/Cape_Glossy_Starling_0079_129399.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/134.Cape_Glossy_Starling/Cape_Glossy_Starling_0077_129378.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/096.Hooded_Oriole/Hooded_Oriole_0124_90350.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/016.Painted_Bunting/Painted_Bunting_0087_15232.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/016.Painted_Bunting/Painted_Bunting_0076_16765.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/030.Fish_Crow/Fish_Crow_0040_25158.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/200.Common_Yellowthroat/Common_Yellowthroat_0077_190990.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/200.Common_Yellowthroat/Common_Yellowthroat_0055_190967.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/065.Slaty_backed_Gull/Slaty_Backed_Gull_0015_796004.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/065.Slaty_backed_Gull/Slaty_Backed_Gull_0024_796028.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/166.Golden_winged_Warbler/Golden_Winged_Warbler_0042_164437.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/166.Golden_winged_Warbler/Golden_Winged_Warbler_0095_794809.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/007.Parakeet_Auklet/Parakeet_Auklet_0042_795961.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/007.Parakeet_Auklet/Parakeet_Auklet_0065_795969.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/077.Tropical_Kingbird/Tropical_Kingbird_0056_69509.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/167.Hooded_Warbler/Hooded_Warbler_0124_164923.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/060.Glaucous_winged_Gull/Glaucous_Winged_Gull_0014_44832.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/066.Western_Gull/Western_Gull_0110_53861.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/082.Ringed_Kingfisher/Ringed_Kingfisher_0098_73110.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/170.Mourning_Warbler/Mourning_Warbler_0041_795358.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/182.Yellow_Warbler/Yellow_Warbler_0073_176218.txt\n",
      "/home/user_2/AttnGAN/datasets/cub200-2011/preprocessing/text/182.Yellow_Warbler/Yellow_Warbler_0080_176542.txt\n"
     ]
    }
   ],
   "source": [
    "for file in bad_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.randn([2,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6461657 , -0.5135788 , -0.8496051 , -0.49303126, -0.26290402,\n",
       "         1.7020756 ,  1.3532641 , -1.3082935 ,  0.01862434, -0.01803868],\n",
       "       [ 0.6297136 , -1.4580991 , -0.11121239, -0.51820064,  1.6179426 ,\n",
       "        -0.09860552, -1.5733247 , -0.8887586 , -0.5602951 , -0.09386935]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
