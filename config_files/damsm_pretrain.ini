; DAMSM pretraining config file
; all values are underscore seperated and lower cased for consistency

[general]
    seed: 1337
    gpu: 1

[datasets]
name: cub200-2011
path: /home/user_2/AttnGAN/datasets/cub200-2011/preprocessing

[damsm_hyperparameters]
    # Model parameters
    min_word_frequency: 2
    max_caption_length: 18
    embedding_dim: 300
    word_feature_dim: 256
    general_sentence_dim: 256
    LSTM_hidden_dim: 128
    init_value: 0.05
    base_image_size: 299
    dropout_proba: 0.5
    # Optimzer parameters
    encoder_learning_rate: 0.00002
    adam_betas: (0.5, 0.999)
    min_grad_to_clip: 0.3
    # Loss Smoothing hyperparemeters
    gamma1: 5.0
    gamma2: 5.0
    gamma3: 10.0
    # Training hyperparameters
    train: True
    epochs: 600
    batch_size: 40
    record_rate: 5
    log_tensorboard: /home/user_2/AttnGAN/Matan/AttnGAN/src/runs/DAMSM_19_oct
    early_stopping_patience:
    # Paths
    # Directory to save the weights
    weights_dirpath_to_save: /home/user_2/AttnGAN/Matan/AttnGAN/models/damsm/
    # Directory to load the weights. Optional, if not specified, use a normal initialization
    weights_path_to_load:
    ; weights_path_to_load: /home/user_2/AttnGAN/Matan/AttnGAN/models/damsm/10_9_last_epoch_encoders.pt

[attngan_hyperparameters]
    # Model parameters
    base_image_size: 64
    condition_dim: 100
    generator_l1_dim: 128
    attngan_size: 3
    # Optimzer parameters
    discriminator_learning_rate: 0.0002
    generator_learning_rate: 0.0002
    adam_betas: (0.5, 0.999)
    # Loss Smoothing hyperparemeters
    gamma1: 5.0
    gamma2: 5.0
    gamma3: 10.0
    lambda: 5.0
    # Training hyperparameters
    train: False
    epochs: 50
    batch_size: 40
    record_rate: 5
    log_tensorboard: /home/user_2/AttnGAN/Matan/AttnGAN/src/runs/AttnGAN_run3_Sep17
    # Paths
    parameters_path: /home/user_2/AttnGAN/Matan/AttnGAN/models/checkpoint_attngan.pt